{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import WetSpa_main_model_fuctions as WetSpa\n",
    "import WetSpa_static_preproc as WetSpa_prepros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lines taken from PixSWAB\n",
    "# multiprocessing client\n",
    "#applications are broken into smaller routines that run independently,resulting in imporved performance \n",
    "#memory_limit=48GB \n",
    "client = WetSpa.start_multiprocessing()\n",
    "client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da99bcf8",
   "metadata": {},
   "source": [
    "### Main folder of input and output files\n",
    "##### Specify the start and end date for the model run (which usually corresponds to the input files start and end date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines below are taken from PixSWAB\n",
    "MAIN_FOLDER = r''\n",
    "# Create output folder with the time and date\n",
    "time_now = datetime.datetime.now()\n",
    "time_str = time_now.strftime('%Y_%m_%d_%Hh_%Mm')\n",
    "output_dir = 'output_dir_'+str(time_str)\n",
    "dir_out = os.path.join(MAIN_FOLDER,'output', 'nc', output_dir)\n",
    "dir_plots = os.path.join(MAIN_FOLDER,'output', 'plots', output_dir)\n",
    "\n",
    "if not os.path.exists(dir_out):\n",
    "    os.makedirs(dir_out)\n",
    "    \n",
    "if not os.path.exists(dir_plots):\n",
    "    os.makedirs(dir_plots)\n",
    "\n",
    "log_file_path = os.path.join(dir_out, 'log_file.txt')\n",
    "log_file = WetSpa._log_create(log_file_path)\n",
    "\n",
    "Startdate='2010-06-01'\n",
    "Enddate='2017-05-31'#'2018-05-31'\n",
    "\n",
    "log_file.write('{:>26s}: {}\\n'.format('Start date', str(Startdate)))\n",
    "log_file.write('{:>26s}: {}\\n'.format('End date', str(Enddate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1455fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calibration parameters \n",
    "\n",
    "#correction factor for PET \n",
    "#range: close to 1 (0.3-2.0)\n",
    "k_ep=0.62\n",
    "\n",
    "#exponent refelction the effect of rainfall intensity or actual surface runoff coefficient when rainfal intesnity is very small\n",
    "#range: 0.01 -15.00\n",
    "k_run=4.51\n",
    "\n",
    "# threshold of rainfall intensity\n",
    "#range: 1-700\n",
    "P_max= 220.77\n",
    "\n",
    "#soil moisture ratio relative to the field capacity for setting up the initial soil moisture content\n",
    "#range: negative or 0.1 - 3.0 \n",
    "k_ss = 0.30\n",
    "\n",
    "#inital GW storage in depth [mm]\n",
    "#range: 1-500\n",
    "g0 = 262.30\n",
    "\n",
    "#maximum GW storage in depth [mm]\n",
    "g_max = 575.59\n",
    "\n",
    "#interflow scaling factor reflecting the effect of organic material and root system in the topsoil layer on the horizontal hydraulic conductivity\n",
    "#range: 0.1-20\n",
    "ki = 3.11\n",
    "\n",
    "#time interval in h \n",
    "dt_hours = 720\n",
    "\n",
    "#GW flow recession coefficient (reflects GW recession regime for entire catchment)\n",
    "#range: 1*10^-6 to 1*10^-1\n",
    "kg = 0.028\n",
    "\n",
    "#following parameters are currently not used in the model, but can be implemented \n",
    "#base temoerature for estimating snowmelt, in which the precipitation shifts from rain to snow (negative value)\n",
    "T0 = -1.000\n",
    "#rainfall degree-day coefficient determining the rate of snowmelt caused by rainfall (negative value)\n",
    "k_rain = 0.00\n",
    "#temperature degree-day coefficient calculating snowmelt (negative value)\n",
    "k_snow = 2.00\n",
    "\n",
    "#Parameters for the incoorporation of waterbodies and irrigated land use (crop coefficient and irrigation efficiency)\n",
    "#kc for water bodies -> this is to incooperate the ET of water bodies \n",
    "kcw= 0.8 #0.95#1.05\n",
    "\n",
    "#kc for irrigated forest \n",
    "kcf= 0.2\n",
    "\n",
    "#irrigation efficiency -> this depends on the irrigation method that is predomantely used in the study area \n",
    "ieff= 0.7\n",
    "\n",
    "csv_lcc_info = os.path.join(MAIN_FOLDER,\"input/csvs/ETref.csv\")\n",
    "df=pd.read_csv(csv_lcc_info,sep=',',index_col=0)\n",
    "ET0_dict = df.T.to_dict('list')\n",
    "log_file.write('{:>26s}: {}\\n'.format('LCC info file path', str(csv_lcc_info)))\n",
    "\n",
    "#Lines below are taken from PixSWAB\n",
    "period = {\n",
    "         's': Startdate,\n",
    "         'e': Enddate\n",
    "         }\n",
    "wdir=r''\n",
    "\n",
    "input_files =  { # SB! sub-catchment\n",
    "                'p_in' : os.path.join(MAIN_FOLDER,\"input/maps/p_CHIRPS_monthly.nc\"),\n",
    "                 'lu_in' : os.path.join(MAIN_FOLDER,\"input/maps/lcc_WetSpa.nc\"),\n",
    "                'et_act_in' : os.path.join(MAIN_FOLDER,\"input/maps/et_SSEBop_monthly.nc\"),\n",
    "                 'pet_in' : os.path.join(MAIN_FOLDER,\"input/maps/ret_monthly.nc\"),\n",
    "                'tmin_in' : os.path.join(MAIN_FOLDER,\"input/maps/Tmin_monthly.nc\"),\n",
    "                'tmax_in' : os.path.join(MAIN_FOLDER,\"input/maps/Tmax_monthly.nc\"),\n",
    "                 'DEM' : os.path.join(MAIN_FOLDER,\"input\\maps\\K3_DEM.tif\"), \n",
    "                'soil' : os.path.join(MAIN_FOLDER,\"input\\maps\\K3_soil_final.tif\")\n",
    "                }\n",
    "parameters = {\n",
    "    'k_ep':k_ep,\n",
    "    'k_run':k_run,\n",
    "    'P_max':P_max,\n",
    "    'k_ss':k_ss,\n",
    "    'ki':ki,\n",
    "    'dt_hours':dt_hours,\n",
    "    'kg':kg,\n",
    "    'g0':g0,\n",
    "    'g_max':g_max,\n",
    "    'T0':T0,\n",
    "    'k_rain':k_rain,\n",
    "    'k_snow':k_snow,\n",
    "    'kcw': kcw,\n",
    "    'kcf': kcf,\n",
    "    'ieff': ieff\n",
    "    }\n",
    "\n",
    "#all possible outputs: \n",
    "output = ['ET', 'SRO', 'ET_diff', 'ET_diff_noirr', 'ETg', 'ETb', 'Sup', 'ETi', 'ETs', 'ETd', 'ETirr', 'SM', 'ET_per', 'ET_per_noirr']\n",
    "\n",
    "#output = ['ET_nirr']\n",
    "\n",
    "# encoding for writing dataset to file\n",
    "latchunk = 200\n",
    "lonchunk = 200\n",
    "timechunk = 1\n",
    "chunks = {'time':timechunk,'latitude':latchunk, 'longitude':lonchunk}\n",
    "\n",
    "# read the sizes of the precipitation dataset\n",
    "with xr.open_dataset(input_files['p_in']) as xds:\n",
    "    latchunk = min(latchunk,xds.latitude.size)\n",
    "    lonchunk = min(lonchunk,xds.longitude.size)\n",
    "    xds.close()\n",
    "\n",
    "# chunks = [timechunk,latchunk, lonchunk]\n",
    "comp = dict(zlib=True, complevel=9, least_significant_digit=2, chunksizes=list(chunks.values()))  \n",
    "\n",
    "encoding_output = dict(\n",
    "                dtype =  np.float32,\n",
    "                _FillValue = np.nan,\n",
    "                scale_factor = np.float32(1.0),\n",
    "                add_offset = np.float32(0.0),\n",
    "                zlib = True,\n",
    "                complevel = 9,\n",
    "                least_significant_digit = 2,\n",
    "                chunksizes=tuple(chunks.values())\n",
    "            )\n",
    "\n",
    "wetspa_params = {\n",
    "    'period':period,\n",
    "    'wdir':wdir, \n",
    "    'input_files':input_files,\n",
    "    'parameters':parameters,\n",
    "    'chunks':chunks,\n",
    "    'output':output,\n",
    "    'ET0_dict':ET0_dict\n",
    "  }\n",
    "\n",
    "log_file.write('{:>26s}:\\n'.format('Input files and parameters'))\n",
    "# for key, value in input_files.items():\n",
    "#     log_file.write('{:>26s}: {}\\n'.format(key, str(value)))\n",
    "# for key, value in parameters.items():\n",
    "#     log_file.write('{:>26s}: {}\\n'.format(key, str(value)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22e6de",
   "metadata": {},
   "source": [
    "#### Run the static preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc=WetSpa_prepros.static_preproc(wetspa_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e8e1c",
   "metadata": {},
   "source": [
    "#### Run the WetSpa model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d968f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = WetSpa.wetspa_model(wetspa_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b0507",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4c737",
   "metadata": {},
   "source": [
    "#### Write the output  to netCDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2112fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines below are taken from PixSWAB \n",
    "from dask.distributed import progress\n",
    "import time\n",
    "t1 = time.perf_counter () #returns value (in fractional seconds) of a performance counter \n",
    "\n",
    "log_file.write('{:>26s}:\\n'.format('Output files path'))\n",
    "print(\"writing the netcdf file\")   \n",
    "for r in result: #outputs that were previously selected \n",
    "    if(r is not None):\n",
    "        #print(r)\n",
    "        print(\"* {0}\".format(r.name))\n",
    "        nc_fn=r.name+'.nc'\n",
    "        nc_path=os.path.join(dir_out,nc_fn)\n",
    "        encoding = {r.name: encoding_output}\n",
    "        \n",
    "#         r.to_netcdf(nc_path,encoding=encoding)\n",
    "#         r.close()\n",
    "\n",
    "        delayed_obj = r.to_netcdf(nc_path,encoding=encoding, compute=True)\n",
    "        result = delayed_obj#.persist()\n",
    "        progress(result)\n",
    "        r.close()\n",
    "        name = r.name\n",
    "        log_file.write('{:>26s}: {}\\n'.format(name, str(nc_path)))\n",
    "        # del r\n",
    "print(f\"Writing the netCDF is completed!\")\n",
    "#why is the time important in this step? Time was not measured/taken into consideration for the other steps \n",
    "t2 = time.perf_counter ()\n",
    "time_diff = t2 - t1\n",
    "print(f\"\\nIt took {time_diff} Secs to execute this method\")\n",
    "WetSpa._log_close(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46384e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines below are orginally taken from PixSWAB and adjusted \n",
    "def nc2ts(bf_sr, shape):\n",
    "    ts_all=[]\n",
    "    for nc in bf_sr: #insert paths to your BaseFlow and SRO output netCDF files\n",
    "        var,name = WetSpa.open_nc(nc,chunks)\n",
    "        print('*',name)   #nothing is printed as this is only loading the function\n",
    "\n",
    "        #Clip the datset by shape of the subbasins  \n",
    "        var = var.rio.set_crs(\"epsg:4326\", inplace=True)\n",
    "        var_clipped = var.rio.clip(shape.geometry.values, shape.crs, drop=False)\n",
    "\n",
    "        # Calculate area of the subbasins\n",
    "        area = WetSpa.area_sqkm(var_clipped[0])\n",
    "\n",
    "        # compute volume by multiplying the depth by area\n",
    "        Volume=var_clipped*area*1e-6\n",
    "        Volume = Volume.rename('{0}'.format(var.name))\n",
    "        # sum the volume spatially and convert it dataframe to have timeseries values\n",
    "        ts = Volume.sum(dim=['latitude','longitude'], skipna=True).to_dataframe()\n",
    "        ts_all.append(ts)\n",
    "        var.close()\n",
    "        var_clipped.close()\n",
    "    return ts_all\n",
    "    \n",
    "#print(ts_all) #-> calculation of bf does not seem to be correct -> always 0 (does not change when d (gw store time cons) changes)\n",
    "         \n",
    "infiles = [input_files['p_in']]#,input_files['e_in']\n",
    "outfiles = glob.glob(os.path.join(dir_out,'*.nc'))\n",
    "\n",
    "#files_to_read = ['Base_flow','Surface_Runoff','Incremental_ET_M','Rainfall_ET_M']\n",
    "files_to_read = ['Surface_Runoff']#'Base_flow',\n",
    "x = pd.Series(outfiles)\n",
    "bf_sr = x[x.str.contains('|'.join(files_to_read))]\n",
    "bf_sr = infiles+bf_sr.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9881ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lines below are orginally taken from PixSWAB and adjusted\n",
    "# Lolsur\n",
    "print('Calculating monthly fluxes volume for Lolsur')  \n",
    "\n",
    "# change the shapefile here\n",
    "\n",
    "shapef = os.path.join(MAIN_FOLDER,\"input\\shapefile\\Lolsur_basin.shp\")\n",
    "shape = gpd.read_file(shapef,crs=\"EPSG:4326\")\n",
    "shape = shape.to_crs(\"EPSG:4326\")\n",
    "\n",
    "ts_all = nc2ts(bf_sr, shape)\n",
    "df = pd.concat(ts_all, axis =1)  \n",
    "\n",
    "# read observed outflow\n",
    "path_obs = os.path.join(MAIN_FOLDER,\"input/csvs/discharge_Lolsur_monthly.csv\")\n",
    "Q_m=pd.read_csv(path_obs,sep=',',index_col=0,skiprows=0)\n",
    "\n",
    "Q_m.index=[datetime.datetime.strptime(y,'%d/%m/%Y') for y in Q_m.index]#definition of time was different bevor but gave errors \n",
    "#Q_m = (Q_d*3600*24/1e9).resample('MS').sum()\n",
    "#Q_m['Lolsur_Q_in_cumecs'] = Q_m['Lolsur_Q_in_cumecs']*3600*24/1e9*Q_m.index.days_in_month\n",
    "#Q_m.rename(columns={\"Lolsur_Q_in_cumecs\":\"Lolsur_Q_in_km3/month\"}, inplace=True)\n",
    "Q_m = Q_m[df.index[0]:df.index[-1]]\n",
    "\n",
    "#read additional inflow for K3 \n",
    "path_obs = os.path.join(MAIN_FOLDER,\"input/csvs/inflow_K3_monthly.csv\")\n",
    "Q_m_K3=pd.read_csv(path_obs,sep=',',index_col=0,skiprows=0)\n",
    "Q_m_K3.index=[datetime.datetime.strptime(y,'%d/%m/%Y') for y in Q_m_K3.index]\n",
    "#Q_m_K3['K3_Q_in_m3/s'] = Q_m_K3['K3_Q_in_m3/s']*3600*24/1e9*Q_m_K3.index.days_in_month\n",
    "#Q_m_K3.rename(columns={\"K3_Q_in_m3/s\":\"K3_Q_in_km3/month\"}, inplace=True)\n",
    "Q_m_K3 = Q_m_K3[df.index[0]:df.index[-1]]\n",
    "\n",
    "df2= pd.concat([df, Q_m, Q_m_K3], axis =1)\n",
    "#df2 = df2.dropna()\n",
    "\n",
    "#add additional time series for the plotting \n",
    "NSE = WetSpa.nash_sutcliffe(df2['Lolsur_Q_in_km3/month'], df2['Surface_Runoff_M'] + df2['K3_Q_in_km3/month'])\n",
    "df3 = df2.dropna()\n",
    "KGE = WetSpa.kge(df3['Lolsur_Q_in_km3/month'], df3['Surface_Runoff_M']+df3['K3_Q_in_km3/month'])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "#plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "ax=plt.subplot(211)\n",
    "ax.plot(df2['Lolsur_Q_in_km3/month'], label='Observed discharge at Lolsur')\n",
    "ax.plot(df2.index, df2['Surface_Runoff_M'] + df2['K3_Q_in_km3/month'], label='Modeled discharge')\n",
    "#ax.plot(df2.index, df2['K3_Q_in_km3/month'], label='Inflow K3')\n",
    "ax.set_ylabel('$km^3/month$')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.set_xlim([df2.index[0], df2.index[-1]])\n",
    "\n",
    "leg1 =  plt.legend()\n",
    "plt.title('KGE = {0:.4f}, NSE = {1:.4f}'.format(KGE,NSE))\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "width = 5\n",
    "ax2.bar(df2.index, df2['precipitation'],  width=width, color='g', label = \"Rainfall [km3/month]\",  alpha = 0.9)\n",
    "ax2.set_ylabel('Rainfall', color='g',  fontsize=8)\n",
    "ax2.tick_params('y', colors='g')\n",
    "ax2.invert_yaxis()\n",
    "leg2 = ax2.legend(loc='center right', fontsize=8)\n",
    "ax2.tick_params(labelsize=8)\n",
    "\n",
    "plt.legend(leg2.get_patches()+leg1.get_lines(), \n",
    "        [text.get_text() for text in leg2.get_texts()+leg1.get_texts()], \n",
    "        loc='upper left', fancybox=False, framealpha=0.3, shadow=False, borderpad=0)\n",
    "leg1.remove()\n",
    "\n",
    "ax=plt.subplot(212)\n",
    "ax.plot(np.cumsum(df2['Lolsur_Q_in_km3/month']), label='Cumulative Observed discharge')\n",
    "ax.plot(df2.index, np.cumsum(df2['Surface_Runoff_M']+df2['K3_Q_in_km3/month']), label='Cumulative modeled discharge')\n",
    "#ax.plot(df2.index, np.cumsum(df2['K3_Q_in_km3/month']), label='Cumulative inflow K3')\n",
    "\n",
    "ax.set_ylabel('Flow [$km^3/month$]')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_xlim([df2.index[0], df2.index[-1]])\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(dir_plots, 'Modeled_vs_observed_discharge_Lolsur.png'), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f295a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib.ticker import FixedLocator, FixedFormatte\n",
    "shapef = os.path.join(MAIN_FOLDER,\"input\\shapefile\\Lolsur_basin.shp\")\n",
    "shape = gpd.read_file(shapef,crs=\"EPSG:4326\")\n",
    "shape = shape.to_crs(\"EPSG:4326\")\n",
    "\n",
    "ts_all = nc2ts(bf_sr, shape)\n",
    "df = pd.concat(ts_all, axis =1)  \n",
    "\n",
    "# read observed outflow\n",
    "path_obs = os.path.join(MAIN_FOLDER,\"input/csvs/discharge_Lolsur_monthly.csv\")\n",
    "Q_m=pd.read_csv(path_obs,sep=',',index_col=0,skiprows=0)\n",
    "\n",
    "Q_m.index=[datetime.datetime.strptime(y,'%d/%m/%Y') for y in Q_m.index]#definition of time was different bevor but gave errors \n",
    "Q_m = Q_m[df.index[0]:df.index[-1]]\n",
    "\n",
    "#read additional inflow for K3 \n",
    "path_obs = os.path.join(MAIN_FOLDER,\"input/csvs/inflow_K3_monthly.csv\")\n",
    "Q_m_K3=pd.read_csv(path_obs,sep=',',index_col=0,skiprows=0)\n",
    "Q_m_K3.index=[datetime.datetime.strptime(y,'%d/%m/%Y') for y in Q_m_K3.index]\n",
    "Q_m_K3 = Q_m_K3[df.index[0]:df.index[-1]]\n",
    "\n",
    "df2= pd.concat([df, Q_m, Q_m_K3], axis =1)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "#plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "ax=plt.subplot(211)\n",
    "ax.plot(df2['Lolsur_Q_in_km3/month'], label='Observed discharge at Lolsur')\n",
    "ax.plot(df2.index, df2['Surface_Runoff_M'] + df2['K3_Q_in_km3/month'], label='Modeled discharge')\n",
    "#ax.plot(df2.index, df2['K3_Q_in_km3/month'], label='Inflow K3')\n",
    "ax.set_ylabel('$km^3/month$', fontsize = 14)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_xlim([df2.index[0], datetime.date(2017, 5, 31)])\n",
    "plt.rcParams['font.size'] = 12\n",
    "ax.set_xlabel('Years', fontsize = 14)\n",
    "#ax.set_xticklabels(ax.get_xticklabels(), fontsize = 12)\n",
    "#ax.set_yticklabels(ax.get_yticklabels(), fontsize = 12)\n",
    "\n",
    "title = plt.title('Observed vs. modeled discharge in Lolsur', fontsize = 14)\n",
    "leg1 =  plt.legend(fontsize = 12)\n",
    "plt.savefig(os.path.join(dir_plots, 'Time_Series_WetSpa.png'), bbox_inches='tight', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a9123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outflow of WetSpa is used as input for WA+ sheet generation:\n",
    "df['Discharge']=df2['Surface_Runoff_M'] + df2['K3_Q_in_km3/month']\n",
    "df['test_out_discharge'] = df['Discharge']*1000000\n",
    "df = df.dropna()\n",
    "\n",
    "df['Inflow']= df2['K3_Q_in_km3/month']\n",
    "df['test_out_inflow'] = df['Inflow']*1000000\n",
    "df = df.dropna()\n",
    "\n",
    "df.to_csv(os.path.join(MAIN_FOLDER,'K3_inflow.csv'), sep = ';', columns = ['test_out_inflow'], header = ['Inflow'])\n",
    "df.to_csv(os.path.join(MAIN_FOLDER,'outflow.csv'), sep = ';', columns = ['test_out_discharge'], header = ['Discharge'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc217785",
   "metadata": {},
   "source": [
    "### Calculating an average tif file for nc files  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "files =  { # SB! sub-catchment\n",
    "                'e_diff' : os.path.join(dir_out, \"Evapotranspiration_percentage_no_irrigation_M.nc\")\n",
    "}\n",
    "ETdiff,_= WetSpa.open_nc(files['e_diff'],chunks)\n",
    "average=ETdiff.mean(dim='time', skipna=True)\n",
    "average_values =np.flipud(average)\n",
    "\n",
    "data = average_values\n",
    "lon = average.coords['longitude'].values\n",
    "lat = average.coords['latitude'].values\n",
    "\n",
    "\n",
    "transform = rasterio.transform.from_bounds(lon.min(), lat.min(), lon.max(), lat.max(), len(lon), len(lat))\n",
    "with rasterio.open(os.path.join(dir_out, \"ET_percentage_average_no_irr.tif\"), 'w', driver='GTiff', height=data.shape[0], width=data.shape[1],\n",
    "                       count=1, dtype=data.dtype, crs='EPSG:4326', transform=transform) as dst:\n",
    "        dst.write(data, 1)\n",
    "print(average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da229781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the whole basin -> do not delete this part!!! \n",
    "#Output need to be changed above first -> calculation of Incremental_ET and Rainfall_ET is needed! \n",
    "print('Calculating monthly fluxes volume for Burhanpur')  \n",
    "\n",
    "infiles = [input_files['p_in'],input_files['e_in']]\n",
    "outfiles = glob.glob(os.path.join(dir_out,'*.nc'))\n",
    "\n",
    "files_to_read = ['Base_flow','Surface_Runoff','Incremental_ET_M','Rainfall_ET_M']\n",
    "#files_to_read = ['Base_flow','Surface_Runoff']\n",
    "x = pd.Series(outfiles)\n",
    "bf_sr = x[x.str.contains('|'.join(files_to_read))]\n",
    "bf_sr = infiles+bf_sr.to_list()\n",
    "\n",
    "\n",
    "# change the shapefile here\n",
    "\n",
    "shapef = os.path.join(MAIN_FOLDER,\"input\\shapefile\\K3.shp\")\n",
    "shape = gpd.read_file(shapef,crs=\"EPSG:4326\")\n",
    "shape = shape.to_crs(\"EPSG:4326\")\n",
    "\n",
    "ts_all = nc2ts(bf_sr, shape)\n",
    "df = pd.concat(ts_all, axis =1)  \n",
    "\n",
    "\n",
    "ts = df.dropna()\n",
    "fig, ax = plt.subplots(figsize=(12,4));\n",
    "ax.plot(ts['precipitation'], color='lightblue', label = 'precipitation');\n",
    "ax.plot(ts['evapotranspiration'], color='k', label = 'evapotranspiration');\n",
    "ax.set_xlim([ts.index[0], ts.index[-1]])\n",
    "labels = ['blue ET', 'green ET']\n",
    "ax.stackplot(ts.index, ts['Incremental_ET_M'], ts['Rainfall_ET_M'], labels = labels, colors=['royalblue','limegreen']);\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(dir_plots, 'et_green_blue1.png'), bbox_inches='tight', dpi=600)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4));\n",
    "plt.plot(ts['Incremental_ET_M'], color='royalblue', label = 'blue ET');\n",
    "plt.plot(ts['Rainfall_ET_M'], color='limegreen', label = 'green ET');\n",
    "labels = ['precipitation', 'evapotranspiration']\n",
    "ax.stackplot(ts.index,abs(ts['precipitation'] - ts['evapotranspiration']), color='grey')\n",
    "ax.set_xlim([ts.index[0], ts.index[-1]])\n",
    "plt.plot(ts['precipitation'] - ts['evapotranspiration'], 'k--', label = 'water yield')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(dir_plots, 'et_green_blue2.png'), bbox_inches='tight', dpi=600)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
